{
  "id": "ckad-a-040",
  "title": "Advanced Node Affinity and Anti-Affinity",
  "description": "Design a complex pod scheduling strategy using ||node affinity||, ||pod affinity||, and ||pod anti-affinity|| rules. Create a multi-tier application where frontend pods must be scheduled on nodes with SSD storage, database pods should avoid being co-located with each other, and cache pods should be placed close to frontend pods. Use both required and preferred scheduling rules to demonstrate different affinity behaviors. This scenario tests understanding of advanced scheduling constraints.",
  "points": 15,
  "timeLimit": 30,
  "category": "Core Concepts",
  "tags": ["node-affinity", "pod-affinity", "anti-affinity", "scheduling", "topology", "advanced"],
  "infrastructure": {
    "namespaces": ["scheduling-demo"],
    "resources": ["Pod", "Node labels"],
    "prerequisites": ["Multi-node cluster with labeled nodes"]
  },
  "solution": {
    "steps": [
      "1. Create namespace and label nodes:",
      "   kubectl create namespace scheduling-demo",
      "   kubectl label nodes node1 storage-type=ssd",
      "   kubectl label nodes node2 storage-type=hdd",
      "   kubectl get nodes --show-labels | grep storage-type",
      "2. Create frontend pods with required node affinity for SSD:",
      "   kubectl apply -f - <<EOF",
      "   apiVersion: v1",
      "   kind: Pod",
      "   metadata:",
      "     name: frontend-1",
      "     namespace: scheduling-demo",
      "     labels:",
      "       tier: frontend",
      "   spec:",
      "     affinity:",
      "       nodeAffinity:",
      "         requiredDuringSchedulingIgnoredDuringExecution:",
      "           nodeSelectorTerms:",
      "           - matchExpressions:",
      "             - key: storage-type",
      "               operator: In",
      "               values:",
      "               - ssd",
      "     containers:",
      "     - name: frontend",
      "       image: nginx:alpine",
      "   EOF",
      "3. Create database pods with pod anti-affinity:",
      "   kubectl apply -f - <<EOF",
      "   apiVersion: v1",
      "   kind: Pod",
      "   metadata:",
      "     name: database-1",
      "     namespace: scheduling-demo",
      "     labels:",
      "       tier: database",
      "   spec:",
      "     affinity:",
      "       podAntiAffinity:",
      "         requiredDuringSchedulingIgnoredDuringExecution:",
      "         - labelSelector:",
      "             matchExpressions:",
      "             - key: tier",
      "               operator: In",
      "               values:",
      "               - database",
      "           topologyKey: kubernetes.io/hostname",
      "     containers:",
      "     - name: database",
      "       image: postgres:13",
      "       env:",
      "       - name: POSTGRES_PASSWORD",
      "         value: password",
      "   EOF",
      "   kubectl apply -f - <<EOF",
      "   apiVersion: v1",
      "   kind: Pod",
      "   metadata:",
      "     name: database-2",
      "     namespace: scheduling-demo",
      "     labels:",
      "       tier: database",
      "   spec:",
      "     affinity:",
      "       podAntiAffinity:",
      "         requiredDuringSchedulingIgnoredDuringExecution:",
      "         - labelSelector:",
      "             matchExpressions:",
      "             - key: tier",
      "               operator: In",
      "               values:",
      "               - database",
      "           topologyKey: kubernetes.io/hostname",
      "     containers:",
      "     - name: database",
      "       image: postgres:13",
      "       env:",
      "       - name: POSTGRES_PASSWORD",
      "         value: password",
      "   EOF",
      "4. Create cache pods with pod affinity to frontend:",
      "   kubectl apply -f - <<EOF",
      "   apiVersion: v1",
      "   kind: Pod",
      "   metadata:",
      "     name: cache-1",
      "     namespace: scheduling-demo",
      "     labels:",
      "       tier: cache",
      "   spec:",
      "     affinity:",
      "       podAffinity:",
      "         requiredDuringSchedulingIgnoredDuringExecution:",
      "         - labelSelector:",
      "             matchExpressions:",
      "             - key: tier",
      "               operator: In",
      "               values:",
      "               - frontend",
      "           topologyKey: kubernetes.io/hostname",
      "     containers:",
      "     - name: cache",
      "       image: redis:alpine",
      "   EOF",
      "5. Create additional pods for testing:",
      "   kubectl apply -f - <<EOF",
      "   apiVersion: v1",
      "   kind: Pod",
      "   metadata:",
      "     name: backend-1",
      "     namespace: scheduling-demo",
      "     labels:",
      "       tier: backend",
      "   spec:",
      "     affinity:",
      "       nodeAffinity:",
      "         preferredDuringSchedulingIgnoredDuringExecution:",
      "         - weight: 100",
      "           preference:",
      "             matchExpressions:",
      "             - key: storage-type",
      "               operator: In",
      "               values:",
      "               - hdd",
      "     containers:",
      "     - name: backend",
      "       image: httpd:alpine",
      "   EOF",
      "6. Verify pod scheduling and affinity rules:",
      "   kubectl get pods -n scheduling-demo -o wide",
      "   kubectl describe pod frontend-1 -n scheduling-demo | grep -A 10 'Node-Selectors'",
      "   kubectl describe pod database-1 -n scheduling-demo | grep -A 10 'Affinity'",
      "   kubectl get pods -n scheduling-demo --field-selector=status.phase=Running"
    ]
  },
  "validations": [
    {
      "command": "kubectl get pods -n scheduling-demo -l tier=frontend -o jsonpath='{.items[0].spec.nodeName}' | xargs kubectl get node --show-labels | grep storage-type=ssd",
      "expected": "ssd-label-found",
      "points": 3,
      "description": "Frontend pods are scheduled on SSD nodes"
    },
    {
      "command": "kubectl get pods -n scheduling-demo -l tier=database -o jsonpath='{.items[*].spec.nodeName}' | tr ' ' '\\n' | sort | uniq | wc -l",
      "expected": "2",
      "points": 4,
      "description": "Database pods are on different nodes (anti-affinity)"
    },
    {
      "command": "kubectl get pods -n scheduling-demo -l tier=cache -o jsonpath='{.items[0].spec.nodeName}'",
      "expected": "same-as-frontend",
      "points": 3,
      "description": "Cache pods are co-located with frontend pods"
    },
    {
      "command": "kubectl get pods -n scheduling-demo --field-selector=status.phase=Running | wc -l",
      "expected": "7",
      "points": 3,
      "description": "At least 6 pods are running (plus header)"
    },
    {
      "command": "kubectl get pod -n scheduling-demo -l tier=frontend -o jsonpath='{.items[0].spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms[0].matchExpressions[0].key}'",
      "expected": "storage-type",
      "points": 2,
      "description": "Frontend pods have correct node affinity configuration"
    }
  ]
}