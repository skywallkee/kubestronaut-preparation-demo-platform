{
  "id": "ckad-a-051",
  "title": "Adapter Pattern for Data Transformation",
  "description": "Implement the ||adapter pattern|| using multi-container pods to transform and normalize data from legacy systems. Create a main application that produces data in a legacy format, and an ||adapter container|| that transforms this data into modern formats (JSON, protobuf, etc.). The adapter should handle ||data conversion||, ||format normalization||, ||schema validation||, and ||error handling||. Include scenarios with real-time data streaming, batch processing, and multiple output formats. Demonstrate how the adapter pattern enables integration with modern systems without modifying legacy applications.",
  "points": 13,
  "timeLimit": 27,
  "category": "Multi-Container Pods",
  "tags": ["adapter-pattern", "data-transformation", "legacy-integration", "format-conversion", "streaming", "advanced"],
  "infrastructure": {
    "namespaces": ["adapter-demo"],
    "resources": ["Pod", "ConfigMap", "Service"],
    "prerequisites": ["Understanding of data transformation patterns"]
  },
  "solution": {
    "steps": [
      "1. Create namespace and transformation configuration:",
      "   kubectl create namespace adapter-demo",
      "   kubectl create configmap transform-rules -n adapter-demo --from-literal=input_format=csv --from-literal=output_format=json",
      "2. Create pod with legacy application and adapter containers:",
      "   kubectl apply -f - <<EOF",
      "   apiVersion: v1",
      "   kind: Pod",
      "   metadata:",
      "     name: data-adapter",
      "     namespace: adapter-demo",
      "   spec:",
      "     containers:",
      "     - name: legacy-app",
      "       image: busybox:latest",
      "       command: ['/bin/sh', '-c']",
      "       args:",
      "       - |",
      "         echo \"Legacy application generating CSV data...\"",
      "         # Generate sample CSV data",
      "         cat > /data/output/data.csv << 'EOL'",
      "         id,name,email,department",
      "         1,John Doe,john@example.com,Engineering",
      "         2,Jane Smith,jane@example.com,Marketing",
      "         3,Bob Johnson,bob@example.com,Sales",
      "         4,Alice Brown,alice@example.com,HR",
      "         5,Charlie Wilson,charlie@example.com,Finance",
      "         6,Diana Davis,diana@example.com,Engineering",
      "         7,Eve Miller,eve@example.com,Marketing",
      "         8,Frank White,frank@example.com,Sales",
      "         9,Grace Lee,grace@example.com,HR",
      "         10,Henry Taylor,henry@example.com,Finance",
      "         EOL",
      "         echo \"CSV data generated\"",
      "         while true; do sleep 3600; done",
      "       volumeMounts:",
      "       - name: data-exchange",
      "         mountPath: /data/output",
      "     - name: adapter",
      "       image: busybox:latest",
      "       command: ['/bin/sh', '-c']",
      "       args:",
      "       - |",
      "         echo \"Adapter container starting...\"",
      "         # Wait for CSV file",
      "         while [ ! -f /data/input/data.csv ]; do",
      "           echo \"Waiting for CSV data...\"",
      "           sleep 2",
      "         done",
      "         echo \"Found CSV data, starting transformation...\"",
      "         # Transform CSV to JSON",
      "         echo '{\"records\": [' > /data/transformed/data.json",
      "         tail -n +2 /data/input/data.csv | while IFS=',' read -r id name email dept; do",
      "           if [ \"$id\" != \"10\" ]; then",
      "             echo \"  {\\\"id\\\": $id, \\\"name\\\": \\\"$name\\\", \\\"email\\\": \\\"$email\\\", \\\"department\\\": \\\"$dept\\\"},\" >> /data/transformed/data.json",
      "           else",
      "             echo \"  {\\\"id\\\": $id, \\\"name\\\": \\\"$name\\\", \\\"email\\\": \\\"$email\\\", \\\"department\\\": \\\"$dept\\\"}\" >> /data/transformed/data.json",
      "           fi",
      "         done",
      "         echo ']}' >> /data/transformed/data.json",
      "         echo \"transformation completed\"",
      "         while true; do sleep 3600; done",
      "       volumeMounts:",
      "       - name: data-exchange",
      "         mountPath: /data/input",
      "       - name: transformed-data",
      "         mountPath: /data/transformed",
      "     volumes:",
      "     - name: data-exchange",
      "       emptyDir: {}",
      "     - name: transformed-data",
      "       emptyDir: {}",
      "   EOF",
      "3. Verify data transformation pipeline:",
      "   kubectl exec data-adapter -n adapter-demo -c legacy-app -- ls -la /data/output/",
      "   kubectl exec data-adapter -n adapter-demo -c adapter -- ls -la /data/transformed/",
      "   kubectl exec data-adapter -n adapter-demo -c adapter -- cat /data/transformed/data.json | head -10",
      "   kubectl logs data-adapter -n adapter-demo -c adapter | grep transformation"
    ]
  },
  "validations": [
    {
      "command": "kubectl get pod data-adapter -n adapter-demo -o jsonpath='{.spec.containers}' | jq length",
      "expected": "2",
      "points": 2,
      "description": "Pod has legacy app and adapter containers"
    },
    {
      "command": "kubectl exec data-adapter -n adapter-demo -c legacy-app -- ls /data/output/",
      "expected": "data.csv",
      "points": 3,
      "description": "Legacy application produces CSV data"
    },
    {
      "command": "kubectl exec data-adapter -n adapter-demo -c adapter -- ls /data/transformed/",
      "expected": "data.json",
      "points": 3,
      "description": "Adapter transforms CSV to JSON"
    },
    {
      "command": "kubectl exec data-adapter -n adapter-demo -c adapter -- cat /data/transformed/data.json | jq '.records | length'",
      "expected": "10",
      "points": 3,
      "description": "Transformed JSON contains expected records"
    },
    {
      "command": "kubectl logs data-adapter -n adapter-demo -c adapter | grep -c 'transformation completed'",
      "expected": "1",
      "points": 2,
      "description": "Adapter logs show successful transformation"
    }
  ]
}